{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/text/transformer\n",
    "# https://arxiv.org/abs/2001.08317\n",
    "# https://arxiv.org/pdf/1907.00235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY (7029, 7)\n"
     ]
    }
   ],
   "source": [
    "# get historical daily price\n",
    "symbol = 'SPY'\n",
    "ticker = yf.Ticker(symbol)\n",
    "history = ticker.history(period=\"max\")\n",
    "print(ticker.ticker,history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2e759751a7b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist_vol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data = np.expand_dims(df.hist_vol.values,axis=-1)\n",
    "scaler.fit(data)\n",
    "transformed = scaler.transform(data)\n",
    "plt.scatter(data,transformed,alpha=0.5)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['price'] = history.Close\n",
    "df['log_ret'] = np.log(df.price) - np.log(df.price.shift(1))\n",
    "df['ret_mean'] = df.log_ret.rolling(21).mean()\n",
    "df['hist_vol'] = df.log_ret.rolling(21).std()*np.sqrt(252)*100\n",
    "df = df.dropna()\n",
    "#df['z_vol']=np.clip(scipy.stats.zscore(df.hist_vol)/10,-1,1)\n",
    "#df['z_ret']=np.clip(scipy.stats.zscore(df.ret_mean)/10,-1,1)\n",
    "# ^^^^ not a fan of z score anymore since... high z score samples will not be large enough. need to l\n",
    "df['z_vol']=df.hist_vol\n",
    "df['z_ret']=df.ret_mean\n",
    "df['month']=df.index.month.values\n",
    "df['day']=df.index.day.values\n",
    "data = df[['z_vol','z_ret','month','day']].values\n",
    "scaler = MinMaxScaler() # same reasoning, also not a fan of minmax scaler\n",
    "scaler.fit(data)\n",
    "transformed = scaler.transform(data)\n",
    "df['z_vol']=transformed[:,0]\n",
    "df['z_ret']=transformed[:,1]\n",
    "df['month']=transformed[:,2]\n",
    "df['day']=transformed[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df.hist_vol),np.std(df.hist_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.z_ret,df.z_vol,alpha=0.5)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['z_vol','z_ret']].plot()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objectiv\n",
    "# given x year span of z_vol, z_ret, predict next y day z_vol and z_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def etl(history):\n",
    "    df = pd.DataFrame()\n",
    "    df['price'] = history.Close\n",
    "    df.index = history.index\n",
    "    df['log_ret'] = np.log(df.price) - np.log(df.price.shift(1))\n",
    "    df['ret_mean'] = df.log_ret.rolling(21).mean()\n",
    "    df['hist_vol'] = df.log_ret.rolling(21).std()*np.sqrt(252)*100\n",
    "    df = df.dropna()\n",
    "    df['z_vol']=df.hist_vol\n",
    "    df['z_ret']=df.ret_mean\n",
    "    df['month']=df.index.month.values\n",
    "    df['day']=df.index.day.values\n",
    "\n",
    "    data = df[['z_vol','z_ret','month','day']].values\n",
    "    scaler = MinMaxScaler() # same reasoning, also not a fan of minmax scaler\n",
    "    scaler.fit(data)\n",
    "    transformed = scaler.transform(data)\n",
    "    df['z_vol']=transformed[:,0]\n",
    "    df['z_ret']=transformed[:,1]\n",
    "    df['month']=transformed[:,2]\n",
    "    df['day']=transformed[:,3]\n",
    "\n",
    "    # add in interest rate.\n",
    "    return np.stack([df.z_vol.values,df.z_ret.values,df.month.values,df.day.values],axis=-1)\n",
    "\n",
    "#look_back=252\n",
    "#look_forward=40\n",
    "look_back=125\n",
    "look_forward=8\n",
    "total_days = look_back+look_forward-1\n",
    "def chunckify(arr):\n",
    "    tmp_list = []\n",
    "    for x in np.arange(total_days,arr.shape[0]-total_days,5):\n",
    "        tmp = arr[x:x+total_days]\n",
    "        if tmp.shape != (total_days,4):\n",
    "            continue\n",
    "        x,y = tmp[:-1*look_forward,:],tmp[-1*look_forward:,:]\n",
    "        tmp_list.append((x,y))\n",
    "    return tmp_list\n",
    "\n",
    "\n",
    "final_list = []\n",
    "symbols = [\n",
    "    'IWM','SPY','QQQ','GLD','SLV',\n",
    "]\n",
    "ticker_list = yf.Tickers(' '.join(symbols))\n",
    "for ticker in ticker_list.tickers:\n",
    "    history = ticker.history(period=\"max\")\n",
    "    print(ticker.ticker,history.shape)\n",
    "    arr = etl(history)\n",
    "    if arr.shape[0] > total_days:\n",
    "        tmp_list = chunckify(arr)\n",
    "        final_list.extend(tmp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_list),final_list[0][0].shape,final_list[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=final_list[0][0]\n",
    "b=final_list[0][1]\n",
    "plt.plot(np.concatenate([a,b]))\n",
    "plt.axvline(look_back,linestyle='--',color='cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([x[0][:,:] for x in final_list],axis=0).astype(np.float32)\n",
    "y = np.stack([x[1][:,:] for x in final_list],axis=0).astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/transformer\n",
    "#http://jalammar.github.io/illustrated-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exists = os.path.exists('X_train.npy')\n",
    "if data_exists:\n",
    "    X_train = np.load('X_train.npy')\n",
    "    X_test = np.load('X_test.npy')\n",
    "    y_train = np.load('y_train.npy')\n",
    "    y_test = np.load('y_test.npy')\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.yml','r') as f:\n",
    "    history = yaml.unsafe_load(f.read())\n",
    "\n",
    "df = pd.DataFrame(history)\n",
    "print(df.shape)\n",
    "plt.figure(0)\n",
    "df[['train_loss','val_loss']].plot(alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.figure(1)\n",
    "df[['train_accuracy0','val_accuracy0']].plot(alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.figure(2)\n",
    "df[['train_accuracy1','val_accuracy1']].plot(alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.figure(3)\n",
    "df[['train_accuracy2','val_accuracy2']].plot(alpha=0.5)\n",
    "plt.grid(True)\n",
    "plt.figure(4)\n",
    "df[['train_accuracy3','val_accuracy3']].plot(alpha=0.5)\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = 125\n",
    "target_seq_len = 10\n",
    "batch_size = 32\n",
    "\n",
    "num_layers = 4\n",
    "d_model = 4\n",
    "dff = 4\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "\n",
    "from train import Transformer,CustomSchedule,create_masks\n",
    "\n",
    "loss_object = tf.keras.losses.Huber(delta=2.0)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    loss_ = loss_object(real, pred)\n",
    "    return tf.reduce_sum(loss_)\n",
    "\n",
    "#\"acc...\"\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = loss_object(real, pred)\n",
    "    return tf.reduce_sum(accuracies)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "#############\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "########\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff ,rate=dropout_rate,target_seq_len=target_seq_len)\n",
    "\n",
    "########\n",
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp,tar):\n",
    "    \n",
    "    enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp[:,:,0], tar[:,:,0])\n",
    "    \n",
    "    predictions, attention_weights = transformer(inp, tar,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 look_ahead_mask,\n",
    "                                                 dec_padding_mask)\n",
    "\n",
    "    return predictions, attention_weights\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "\n",
    "#translate(\"este é um problema que temos que resolver.\")\n",
    "#print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = False# True#\n",
    "for x in np.arange(0,20,1):\n",
    "    inp,tar = X_test[x,:].squeeze(),y_test[x,:].squeeze()\n",
    "    inp = np.expand_dims(inp,axis=0)\n",
    "    tar = np.expand_dims(tar,axis=0)\n",
    "    print(inp.shape,tar.shape)\n",
    "    result, attention_weights = evaluate(inp,tar)\n",
    "    \n",
    "    for ind,subplot,title in [\n",
    "        (0,141,'volatility'),\n",
    "        (1,142,'ret_mean'),\n",
    "        (2,143,'month'),\n",
    "        (3,144,'day')\n",
    "\n",
    "    ]:\n",
    "        plt.figure(x,figsize=(10,2.5))\n",
    "        plt.subplot(subplot)\n",
    "        pred = result.numpy().squeeze()[:,ind]\n",
    "        true = tar.squeeze()[:,ind]\n",
    "        if norm:\n",
    "            pred/=result.numpy().squeeze()[0,ind]\n",
    "            true/=tar.squeeze()[0,ind]\n",
    "        plt.plot(pred,label='pred')\n",
    "        plt.plot(true,linestyle='--',label='true')\n",
    "        plt.legend()\n",
    "        plt.title(title)\n",
    "        plt.grid(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
